#!/usr/bin/env python3
#input is job file in csv format
#launch the ROSETTA CM pipeline
#Shawn Shen 01222021

from pathlib import Path
from database_access import StatusEditor
import py_thread
import fragments
import hybridize_mover
import tempfile

class launcher():

    def __init__(self, MHC_class, work_dir, msa_file_A, msa_file_B=None, numofjobs=10):
        self.numofjobs = numofjobs
        self.MHC_class = MHC_class
        self.work_dir = work_dir
        self.msa_file_A = msa_file_A
        self.msa_file_B = msa_file_B

        if MHC_class == 1:
            self.pdb_dir = str(Path(__file__).parent.parent.resolve())+"/database/Class_I/templates"

            if msa_file_B is not None:
                raise ValueError("2 MSA files provided for MHC class I !!")
        
        elif MHC_class == 2:
            self.pdb_dir = str(Path(__file__).parent.parent.resolve())+"/database/Class_II/templates"

            if msa_file_B is None:
                raise ValueError("2 MSA files needed for MHC class II !!")

    def pipeline1(self, row):
        # pipeline for MHC class I
        print(f"---{row['Allele']}---")
        allele_dir = f"{self.work_dir}/{row['Allele']}"
        
        print("...threading...")
        py_thread.main(f"{self.pdb_dir}/{row['Best_template']}.pdb", "A", f"{allele_dir}/A_chain.aln", f"{allele_dir}/target.pdb")
        
        print("...picking fragments...")
        ticket, status = fragments.pbs_run(f"{allele_dir}/target.fasta", self.msa_file_A, row['A_index'], row['A_cov'])
        # index in job_file is 1-based, same for MHC class II

        if status == 0:
            #default fragment file names are X.200.3(9)mers, set in fragments.py
            print("...launching hybridize mover...")
            hybridize_mover.pbs_run(f"{allele_dir}/target.fasta", f"{allele_dir}/target.pdb", f"{allele_dir}/target.200.3mers", f"{allele_dir}/target.200.9mers", ticket.strip().split(" ")[-1])
        else:
            raise ValueError("fragments picker failed")
        print("===job submitted===")

        return 0

    def pipeline2(self, row):
        # pipeline for MHC class II
        print(f"---{row['Allele']}---")
        allele_dir = f"{self.work_dir}/{row['A_gene']}/{row['B_gene']}"

        print("...threading...")
        thread_temp = tempfile.NamedTemporaryFile()
        py_thread.main(f"{self.pdb_dir}/{row['Best_template']}.pdb", "A", f"{allele_dir}/A_chain.aln", thread_temp.name)
        py_thread.main(thread_temp.name, "B", f"{allele_dir}/B_chain.aln", f"{allele_dir}/target.pdb")

        print("...picking fragments...")
        ticket, status = fragments.pbs_run(f"{allele_dir}/target.link.fasta", [self.msa_file_A, self.msa_file_B], [row['A_index'],row['B_index']], [row['A_cov'],row['B_cov']], multi_chain=1)

        if status == 0:
            #default fragment file names are X.200.3(9)mers, set in fragments.py
            print("...launching hybridize mover...")
            hybridize_mover.pbs_run(f"{allele_dir}/target.fasta", f"{allele_dir}/target.pdb", f"{allele_dir}/target.200.3mers", f"{allele_dir}/target.200.9mers", ticket.strip().split(" ")[-1])
        else:
            raise ValueError("fragments picker failed")
        print("===job submitted===")

        return 0

def main(job_file, work_dir, msa_file_A, msa_file_B, numofjobs, query_list_file):

    if query_list_file is None:
        print("Mode: sequencial")
    else:
        print("Mode: list")

    job = StatusEditor(job_file, work_dir)

    queue = job.launch_queue(numofjobs, query_list_file)
    run = launcher(job.MHC_class, job.work_dir, msa_file_A, msa_file_B, numofjobs)
    good_queue = []

    for record in queue:
        row = record[1]

        if job.MHC_class == 1:
            run.pipeline1(row)
        elif job.MHC_class == 2:
            run.pipeline2(row)
        else:
            raise ValueError(f"MHC class not recognized: {job.MHC_class}")
        good_queue.append(record)

    job.queue_confirm(good_queue)

    return 0

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="job launcher")
    parser.add_argument("job_file", help="job file generated by database_accesss.py")
    parser.add_argument("msa", nargs="+", help="msa file(s). 1 for class I and 2 for class I")
    parser.add_argument("-d", "--dir", required=False, help="working directory that contains ")
    parser.add_argument("-l", "--list", required=False, help="run by a list of alleles. one allele each line")
    parser.add_argument("-n", "--num", default=10, required=False, type=int, help="number of jobs each time")

    args = parser.parse_args()

    if len(args.msa) == 1:
        main(args.job_file, args.dir, args.msa[0], None, args.num, args.list)
    elif len(args.msa) == 2:
        main(args.job_file, args.dir, args.msa[0], args.msa[1], args.num, args.list)
    else:
        raise ValueError("too many inputs !!")
